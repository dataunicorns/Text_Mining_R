---
title: "Crimson Code"
author: "Prathyusha"
date: "August 9, 2017"
output: html_document
---

```{r}

#importing the data
crimson_text_corpus <- read.csv("C:\\Users\\prathyusha\\Desktop\\cleaned_crimson_data_2.csv", header = T, sep=",")
#crimson_text_corpus

library(tm)

#getwd()
#setwd('/home/fcbanalytics/Prathy_Practice')
crimson_text_corpus <- data.frame(crimson_text_corpus$doc_id,crimson_text_corpus$Contents,crimson_text_corpus$Name)

# To asssign a new colum with 0 values
#crimson_text_corpus <- as.data.frame(append(crimson_text_corpus, 0, after = 4))
crimson_text_corpus <- setNames(crimson_text_corpus,c("Post_id", "contents" ,"Name"))
crimson_text_corpus$contents <- as.character(crimson_text_corpus$contents)
crimson_text_corpus$Post_id <- as.character(crimson_text_corpus$Post_id)
crimson_text_corpus$Name <- as.character(crimson_text_corpus$Name)

```

```{r}

# To find out the names which starts with Dr

Dr <- grepl("Dr.", crimson_text_corpus$Name)
#summary(Dr)

# row number
find1 <- grep("Dr.", crimson_text_corpus$Name)
#find1

# To print the names
#find = crimson_text_corpus$Name[find1] or 
find <- crimson_text_corpus$Name[grep("Dr.", crimson_text_corpus$Name)]
#find

# to find out the names with Dr. and Dr 

crimson_text_corpus$is_doc <- grepl("Dr\\Q.\\E",crimson_text_corpus$Name) # to know the dr. terms

crimson_text_corpus$is_doc2 <- grepl("Dr\\Q \\E",crimson_text_corpus$Name) # to know the dr terms

summary(crimson_text_corpus$is_doc)

summary(crimson_text_corpus$is_doc2)

#ifelse statement to assign the 0 and 1 values to new code column (value matching)

crimson_text_corpus$code <- ifelse(crimson_text_corpus$is_doc %in% c(TRUE)| crimson_text_corpus$is_doc2 %in% c(TRUE), "Doctor","consumer")

```

```{r}


#Run after creating ifelse statement
crimson_text_corpus$code <- as.character(crimson_text_corpus$code)

#hcp$IS_GYN <- ifelse(hcp$IS_GYN1 %in% c(TRUE) & hcp$is_texas %in% c(1) & hcp$target_zips %in% 'target' & 
# hcp$GENDER_CODE_3017 %in% "F", TRUE, FALSE)

#hcp$is_hcp <- ifelse(is_sermo %in% c(TRUE)| is_crimson_and_dr_in_name %in% c(TRUE),1,0)

#df <- subset(df, select = c(a,c)) for reference

crimson_text_corpus <- data.frame(crimson_text_corpus)
crimson_text_corpus <- crimson_text_corpus[,-(3:5),drop=FALSE]


crimson <- data.frame(crimson_text_corpus)
crimson$dmeta1 <- 1:8891
crimson$dmeta2 <- letters[1:8891]
View(crimson)

```


```{r}

TextContent = crimson$contents

# create term frequency matrix using functions from tm library
doc_corpus <- Corpus( VectorSource(TextContent) )
control_list <- list(removePunctuation = TRUE, stopwords = TRUE, tolower = TRUE)
tdm <- TermDocumentMatrix(doc_corpus, control = control_list)

tf <- as.matrix(tdm)


#The next Step is to Create the Inverse Term frequency Matrix with the above inputs

# idf
idf <- log( ncol(tf) / ( 1 + rowSums(tf != 0) ) ) 

# diagonal matrix
idf <- diag(idf)
  
tf_idf <- crossprod(tf, idf)
colnames(tf_idf) <- rownames(tf)
tf_idf

# 
# 1. [TFIDF] :
# @vector = pass in a vector of documents  
TFIDF <- function(vector) {
	# tf 
	news_corpus  <- Corpus( VectorSource(vector) )
	control_list <- list(removePunctuation = TRUE, stopwords = TRUE, tolower = TRUE)
	tf <- TermDocumentMatrix(news_corpus, control = control_list) %>% as.matrix()

	# idf
	idf <- log( ncol(tf) / ( 1 + rowSums(tf != 0) ) ) %>% diag()
	return( crossprod(tf, idf) )
}

# tf-idf matrix using news' title 
news_tf_idf <- TFIDF(TextContent)
```

```{r}
# 2. [Cosine] :
# distance between two vectors
Cosine <- function(x, y) {
	similarity <- sum(x * y) / ( sqrt( sum(y ^ 2) ) * sqrt( sum(x ^ 2) ) )

	# given the cosine value, use acos to convert back to degrees
	# acos returns the radian, multiply it by 180 and divide by pi to obtain degrees
	return( acos(similarity) * 180 / pi )
}
```

```{r}
# 3. calculate pair-wise distance matrix 
pr_DB$set_entry( FUN = Cosine, names = c("Cosine") )
d1 <- dist(news_tf_idf, method = "Cosine")
pr_DB$delete_entry("Cosine")
```

```{r}
# 4. heirachical clustering 
cluster1 <- hclust(d1, method = "ward.D")
plot(cluster1)
rect.hclust(cluster1, 17)
```

```{r}
crimson_docs <- Corpus(DataframeSource(crimson))

inspect(crimson_docs) # showing error to overcome the error file encoding = latin1 is added at the data importing step

meta(crimson_docs)

```

```{r}


#crimson_docs
library(tm)
writeLines(as.character(crimson_docs[[200]]))

getTransformations()

toSpace <- content_transformer(function (x, pattern) {return (gsub(pattern, " ", x))})


(toSpace <- content_transformer(function (x, pattern) gsub(pattern, " ", x)))

toSpace <- content_transformer(function (crimson_text_corpus, pattern) {return (gsub(pattern, " ", crimson_text_corpus))})

crimson_docs <- tm_map(crimson_docs, toSpace, "-")

crimson_docs <- tm_map(crimson_docs, toSpace, ":")

crimson_docs <- tm_map(crimson_docs, removePunctuation)

crimson_docs <- tm_map(crimson_docs,content_transformer(tolower))
#crimson_docs <- sapply(crimson_docs, tolower)

crimson_docs <- tm_map(crimson_docs, removeNumbers)

crimson_docs <- tm_map(crimson_docs, removeWords, stopwords("english"))
#crimson_docs <- tm_map(crimson_docs,content_transformer(function(x) iconv(x, to='UTF8', sub='byte')))

crimson_docs <- tm_map(crimson_docs, stripWhitespace)

writeLines(as.character(crimson_docs[[200]]))

RemoveURL <- function(x){
  gsub("http[a-z]*","",x)
}

crimson_docs <- tm_map(crimson_docs, content_transformer(RemoveURL))
```

```{r, include=FALSE}


#install.packages("SnowballC")

library(SnowballC)

#install.packages("textstem")
library(textstem)

# stem document 

crimson_docs <- tm_map(crimson_docs, stemDocument)

writeLines(as.character(crimson_docs[[200]]))

crimson_docs <- tm_map(crimson_docs, content_transformer(gsub), pattern = 'someth', replacement = 'something', fixed = T)

str(crimson_docs)

```

```{r}


# Document Term matrix
dtm  <- DocumentTermMatrix(crimson_docs)
dtm

inspect(dtm[1:5,12:22])

# Mining the corpus

freq_words <- colSums(as.matrix(dtm)) # to know the frequency of the words

length(freq_words) # total no of terms

#create sort order (descending)
ord <- order(freq_words,decreasing=TRUE)


#inspect most and least frequently occurring terms
freq_words[head(ord)]

freq_words[tail(ord)]

```

```{r}


# removing any additional words by limiting the word length
#dtmr <-DocumentTermMatrix(crimson_docs, control=list(wordLengths=c(4, 20),
#                                                    bounds = list(global = c(1,50))))
#dtmr
#str(dtmr)


findFreqTerms(dtm,lowfreq=1000) # to find the terms which appears more than 1000 times 

findAssocs(dtm,'chase',0.5) # to check the correlation between the specific term amd other terms in the corpus
findAssocs(dtm,'ancient',0.6)


```

```{r}


# graphics

crimson_graphics =data.frame(term=names(freq_words),occurrences=freq_words)

library(ggplot2)
crimson_plot <- ggplot(subset(crimson_graphics, freq_words>1000), aes(term, occurrences))
crimson_plot <- crimson_plot + geom_bar(stat='identity')
crimson_plot <- crimson_plot + theme(axis.text.x=element_text(angle=45, hjust=1))
crimson_plot

```

```{r}
#wordcloud
#install.packages("RcolorBrewer")
library(wordcloud)

#setting the same seed each time ensures consistent look across clouds
set.seed(42)

#limit words by specifying min frequency, word cloud without any colors 
wordcloud(names(freq_words),freq_words, min.freq=1000)

# To add colors
wc <- wordcloud(names(freq_words),freq_words,min.freq=1000,colors=brewer.pal(6,'Dark2'))
wc <- wordcloud(names(freq_words),freq_words,min.freq=1000,colors=brewer.pal(8,'Dark2'))


```

